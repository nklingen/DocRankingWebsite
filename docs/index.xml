<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Handover Document</title>
    <link>https://nklingen.github.io/DocRankingWebsite/</link>
    <description>Recent content on Handover Document</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language><atom:link href="https://nklingen.github.io/DocRankingWebsite/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Intro</title>
      <link>https://nklingen.github.io/DocRankingWebsite/docs/intro/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://nklingen.github.io/DocRankingWebsite/docs/intro/</guid>
      <description>Intro AboutThis website is a Handover Document by Mikkel Odgaard and Natasha Klingenbrunn for a collaboration project between Denmark&amp;rsquo;s Technical University and Raffle.ai. The final code can be found on Github.
The website is broken down as follows:
 The metric for this project are outline. Next, the Timeline section will discuss the evolution of our project and discuss the rationale behind given design choices. Barlow Twins will be explained both conceptually and implementation-wise.</description>
    </item>
    
    <item>
      <title>Metrics</title>
      <link>https://nklingen.github.io/DocRankingWebsite/docs/metrics/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://nklingen.github.io/DocRankingWebsite/docs/metrics/</guid>
      <description>Metrics To compute top k accuracy
 def k_accuracy(scores, answer_ids, target_answer_ids, k): assert k &amp;gt;= 1 if k == 1: prediction_indices = torch.argmax(scores, dim=1) prediction_answer_ids = answer_ids[prediction_indices] return (prediction_answer_ids == target_answer_ids) elif k &amp;gt; 1: prediction_indices = torch.topk(scores, k).indices prediction_answer_ids = answer_ids[prediction_indices] return (prediction_answer_ids == target_answer_ids.unsqueeze(1)).any(1)  To compute top k average precision score (from Raffle&amp;rsquo;s codebase)
 def batch_map(relevance, k): top_k = relevance[:, :k] batch_size = top_k.size(0) pos = torch.</description>
    </item>
    
    <item>
      <title>Timeline</title>
      <link>https://nklingen.github.io/DocRankingWebsite/docs/timeline/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://nklingen.github.io/DocRankingWebsite/docs/timeline/</guid>
      <description>TimelineThis section will be a general summary of our work and the evolution of the project. The project went through 3 overall phases in regards to the construction of the model.
 Exploratory Data Analysis (EDA) Document Ranking Model Barlow Twins  Exploratory Data AnalysisThe input data contains 4 main pieces of information. The title, the content, the type (questions or conversations) and answer id (the &amp;ldquo;true&amp;rdquo; label). Each piece of information should be analysed due to its importance.</description>
    </item>
    
    <item>
      <title>Model</title>
      <link>https://nklingen.github.io/DocRankingWebsite/docs/model/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://nklingen.github.io/DocRankingWebsite/docs/model/</guid>
      <description>Model The two models are outlined below, where red indicates sub-models with frozen parameters and where blue indicates sub-models with trainable parameters.
  Pre-training Model
  BERT
  Barlow Head
    Training Model
  Pre-training Model
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; Bert &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; Barlow Head
  Ranking Head
   The following section will discuss how the pre-training (with frozen head) and training models are constructed.</description>
    </item>
    
    <item>
      <title>Results</title>
      <link>https://nklingen.github.io/DocRankingWebsite/docs/results/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://nklingen.github.io/DocRankingWebsite/docs/results/</guid>
      <description>ResultsEach model is set to terminate after 10 epochs without improvement of the validation loss. This is what causes the different termination times in the below plots.
Document Ranking ResultsWe begin with the baseline model, otherwise known as BERT with one head. We compare it with plots from our pre-processing experiments: TF-IDF pre-processing by section, or with 512 tokens. These results show us that the optimal pre-processing was just the initial implementation.</description>
    </item>
    
    <item>
      <title>Discussion</title>
      <link>https://nklingen.github.io/DocRankingWebsite/docs/discussion/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://nklingen.github.io/DocRankingWebsite/docs/discussion/</guid>
      <description>Discussion BarlowOur main challange for this project was to implement Barlow on a new domain, and for a new task. The Barlow Loss was originally used to train a model to be robust to noise. However, we implemented it instead to push embeddings closed together in a latent space. Moreover, we see that this implementation was indeed successful as we confirmed from the converging loss, decreasing distance to cluster-centroid, and visual PCA interpretation.</description>
    </item>
    
  </channel>
</rss>
